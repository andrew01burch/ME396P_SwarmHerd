{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and warning supression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 21:09:19.186573: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-14 21:09:19.219600: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-14 21:09:19.387061: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-14 21:09:19.387090: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-14 21:09:19.388151: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-14 21:09:19.471124: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-14 21:09:19.472016: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-14 21:09:20.272525: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import numpy as np\n",
    "import tensorflow as tf  # Import TensorFlow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress TensorFlow INFO and WARNING messages\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial setup and parameter setting\n",
    "\n",
    "This handles preliminary display overhead as well as RL hyperparameters for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screen dimensions\n",
    "WIDTH, HEIGHT = 800, 600\n",
    "\n",
    "visualize = True\n",
    "\n",
    "if visualize:\n",
    "    # Colors\n",
    "    WHITE = (255, 255, 255)\n",
    "    RED = (255, 0, 0)\n",
    "    GREEN = (0, 255, 0)\n",
    "    BLUE = (0, 0, 255)\n",
    "    BLACK = (0, 0, 0)\n",
    "\n",
    "    # Initialize pygame\n",
    "    pygame.init()\n",
    "    # Create the screen and clock objects\n",
    "    screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "    pygame.display.set_caption('Simulation Interation: 0')\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "# Object and target settings\n",
    "object_radius = 15\n",
    "target_radius = 10\n",
    "contact_distance = object_radius\n",
    "\n",
    "# Initial positions\n",
    "object_pos = np.array([WIDTH // 2, HEIGHT // 2], dtype=float)\n",
    "target_pos = np.array([WIDTH // 2, HEIGHT //4])\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon = 1.0  # Exploration rate\n",
    "epsilon_min = 0.01  # Minimum exploration probability\n",
    "epsilon_decay = 0.995  # Exponential decay rate for exploration prob\n",
    "\n",
    "# Hyperparameters\n",
    "n_particles = 10\n",
    "friction_coefficient = -0.05\n",
    "state_size = 4 + 4 + 2  # position and velocity for each particle + object position and velocity + target position\n",
    "action_size = 2  # 2D force vector for each particle\n",
    "learning_rate = 0.005\n",
    "gamma = 0.99  # Discount factor for future rewards\n",
    "action_selection_frequency = 2  # Number of frames to wait before selecting a new action\n",
    "frame_counter = 0  # Counter to keep track of frames\n",
    "collision_occurred = False\n",
    "initial_force_magnitude = 10.0  # Adjust the magnitude of the initial force as needed\n",
    "\n",
    "# RL batch training\n",
    "batch_size = 16\n",
    "max_success_frames = 600 #frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RL methods used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: model_p10.keras\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network for RL\n",
    "for filename in os.listdir(os.getcwd()):\n",
    "    if filename.endswith(\".keras\"):\n",
    "        model = tf.keras.models.load_model(f'{filename}')\n",
    "        print(f'Using model: {filename}')\n",
    "    else:\n",
    "        model = Sequential([\n",
    "            Dense(64, activation='relu', input_shape=(state_size,)),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(action_size, activation='tanh')  # Force vector in range [-1, 1]\n",
    "        ])\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate))\n",
    "\n",
    "# Function to extract the current state\n",
    "def get_state(particle, object, target_pos):\n",
    "    particle_state = np.concatenate([particle.position, particle.velocity])\n",
    "    object_state = np.concatenate([object.position, object.velocity])\n",
    "    state = np.concatenate([particle_state, object_state, target_pos])\n",
    "    return state\n",
    "\n",
    "def apply_action(action, particle):\n",
    "    particle.force = action  # Apply force to the particle\n",
    "\n",
    "def calculate_individual_reward(particle, object, target_pos, collision_occurred_with_object, starting_distance_to_target):\n",
    "    # Current distance between object and target\n",
    "    distance_from_object_to_target = np.linalg.norm(object.position - target_pos)\n",
    "    #change in disctnace between object and target\n",
    "    delta_distance_to_target = starting_distance_to_target - distance_from_object_to_target\n",
    "    #setting the new distance as the old distance to recalculate for the next loop\n",
    " \n",
    "    #if delta_distance_to_target is negative, we are closer to the target and want to reward our model\n",
    "    reward = (delta_distance_to_target)*100 * collision_occurred_with_object\n",
    "\n",
    "    # Penalty for wall collisions\n",
    "    if particle.hit_wall:\n",
    "        reward -= 50  # Adjust the penalty value as needed\n",
    "\n",
    "    # Reward for collision with object\n",
    "    if collision_occurred_with_object:\n",
    "        reward += 100  # Adjust the reward value as needed\n",
    "\n",
    "    return reward\n",
    "\n",
    "def reset_simulation(particle_list, object, sim_iter):\n",
    "    object.position = np.random.rand(2) * [WIDTH, HEIGHT]\n",
    "    object.velocity = np.zeros_like(object.velocity)\n",
    "    for particle in particle_list:\n",
    "        particle.position = np.random.rand(2) * [WIDTH, HEIGHT]\n",
    "        particle.velocity = np.zeros_like(particle.velocity)\n",
    "\n",
    "    if visualize:\n",
    "        pygame.display.set_caption(f'Simulation Interation: {sim_iter}')\n",
    "        # Clear the Pygame event queue to avoid processing stale events\n",
    "        pygame.event.clear()\n",
    "\n",
    "    steps = 0\n",
    "    print(f'--- Simulation Interation #{sim_iter} ---')\n",
    "    sim_iter+=1\n",
    "    starting_distance_to_target = np.linalg.norm(object.position - target_pos)\n",
    "\n",
    "    return steps, sim_iter, starting_distance_to_target\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=10000):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def __str__(self):\n",
    "        buffer_contents = ', '.join([str(item) for item in list(self.buffer)])\n",
    "        return f\"ReplayBuffer (Size: {self.size()}/{self.capacity}) Contents: [{buffer_contents}]\"\n",
    "\n",
    "def train_model(model, replay_buffers, batch_size, gamma):\n",
    "    # Train only if all buffers have enough samples\n",
    "    if all([buffer.size() >= batch_size for buffer in replay_buffers]):\n",
    "        # Sample from each buffer and train\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(\"Training @ =\", current_time)\n",
    "        for buffer in replay_buffers:\n",
    "            minibatch = buffer.sample(batch_size)\n",
    "            for state, action, reward, next_state, done in minibatch:\n",
    "                # print('model.predit and model.fit')\n",
    "                target = reward\n",
    "                if not done:\n",
    "                    target = (reward + gamma * np.amax(model.predict(next_state.reshape(1, -1), verbose = 0)[0]))\n",
    "                target_f = model.predict(state.reshape(1, -1), verbose = 0)\n",
    "                target_f[0][np.argmax(action)] = target\n",
    "                model.fit(state.reshape(1, -1), target_f, epochs=1, verbose = 0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Physics and simulation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Class definition for particles\n",
    "class particle:\n",
    "    def __init__(self, mass=1.0, position=np.array([0.0, 0.0]), radius=5.0, velocity=np.array([0.0, 0.0]), force=np.array([0.0, 0.0])):\n",
    "        self.position = position.astype(float)\n",
    "        self.force = force.astype(float)\n",
    "        self.radius = float(radius)\n",
    "        self.velocity = velocity.astype(float)\n",
    "        self.mass = float(mass)\n",
    "        self.hit_wall = False\n",
    "        \n",
    "    def physics_move(self):\n",
    "        self.hit_wall = False\n",
    "        # Collision with boundaries and physics updates...\n",
    "        # Collision with left or right boundary\n",
    "        if self.position[0] - self.radius < 0 or self.position[0] + self.radius > WIDTH:\n",
    "            self.velocity[0] = -self.velocity[0]\n",
    "            self.position[0] = np.clip(self.position[0], self.radius, WIDTH - self.radius)\n",
    "            self.hit_wall = True\n",
    "        if self.position[1] - self.radius < 0 or self.position[1] + self.radius > HEIGHT:\n",
    "            self.velocity[1] = -self.velocity[1]\n",
    "            self.position[1] = np.clip(self.position[1], self.radius, HEIGHT - self.radius)\n",
    "            self.hit_wall = True\n",
    "            \n",
    "        # Calculate acceleration from force\n",
    "        acceleration = self.force / self.mass\n",
    "\n",
    "        # Update velocity with acceleration\n",
    "        self.velocity += acceleration\n",
    "\n",
    "        # Apply friction to the velocity\n",
    "        self.velocity += friction_coefficient * self.velocity\n",
    "\n",
    "        if np.linalg.norm(self.velocity) < 0.05:\n",
    "            self.velocity = np.zeros_like(self.velocity)\n",
    "\n",
    "        # Update position with velocity\n",
    "        self.position += self.velocity\n",
    "\n",
    "# Helper function to check if a collision occurs between two objects\n",
    "def is_collision(particle1, particle2):\n",
    "    distance = np.linalg.norm(particle1.position - particle2.position)\n",
    "    return distance < (particle1.radius + particle2.radius)\n",
    "\n",
    "def handle_collisions(particles, restitution_coefficient=1):\n",
    "    n = len(particles)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            particle1, particle2 = particles[i], particles[j]\n",
    "            distance_vector = particle1.position - particle2.position\n",
    "            distance = np.linalg.norm(distance_vector).astype(float)\n",
    "            if distance < (particle1.radius + particle2.radius):\n",
    "                # Normalize distance_vector to get collision direction\n",
    "                collision_direction = (distance_vector / distance)\n",
    "                total_mass = float(particle1.mass + particle2.mass)\n",
    "               \n",
    "                overlap = float((particle1.radius + particle2.radius) - distance)\n",
    "                particle1.position += (overlap * (particle2.mass / total_mass)) * collision_direction\n",
    "                particle2.position -= (overlap * (particle1.mass / total_mass)) * collision_direction\n",
    "\n",
    "                # Calculate relative velocity\n",
    "                if distance_vector[0] > 0 or distance_vector[0] > 0:\n",
    "                    relative_velocity = particle2.velocity - particle1.velocity\n",
    "                else:\n",
    "                    relative_velocity = particle1.velocity - particle2.velocity\n",
    "\n",
    "                # Calculate velocity along the direction of collision\n",
    "                velocity_along_collision = np.dot(relative_velocity, collision_direction)\n",
    "                \n",
    "                # Only proceed to update velocities if particles are moving towards each other\n",
    "                if velocity_along_collision > 0:\n",
    "                    # Apply the collision impulse\n",
    "                    mass_factor = (2 * restitution_coefficient) / total_mass\n",
    "                    impulse = velocity_along_collision * collision_direction * mass_factor\n",
    "                    particle1.velocity += impulse * particle2.mass\n",
    "                    particle2.velocity -= impulse * particle1.mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of necessary objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize particle list and object\n",
    "# Initialize particle list with initial force towards the object\n",
    "particle_list = []\n",
    "for _ in range(n_particles):\n",
    "    # Random position for each particle\n",
    "    position = np.random.rand(2) * [WIDTH, HEIGHT]\n",
    "\n",
    "    # Direction from particle to object\n",
    "    direction_to_object = object_pos - position\n",
    "    direction_to_object /= np.linalg.norm(direction_to_object)  # Normalize the direction\n",
    "\n",
    "    # Set initial force towards the object\n",
    "    initial_force = direction_to_object * initial_force_magnitude\n",
    "\n",
    "    # Create particle with initial force\n",
    "    new_particle = particle(mass=10, position=position, velocity=np.random.rand(2), force=initial_force)\n",
    "    particle_list.append(new_particle)\n",
    "object = particle(position=object_pos, radius=object_radius, mass=5)\n",
    "\n",
    "collision_occurred_with_object = False\n",
    "\n",
    "#Initialize replay buffer\n",
    "replay_buffers = [ReplayBuffer(capacity=50000) for _ in range(n_particles)]\n",
    "\n",
    "# Initialize last chosen action\n",
    "last_action = np.zeros(action_size)\n",
    "\n",
    "# Define the maximum duration for a successful run (in milliseconds)\n",
    "consecutive_successes = 0\n",
    "\n",
    "# Initialize previous_distance_to_target\n",
    "starting_distance_to_target = np.linalg.norm(object.position - target_pos)\n",
    "\n",
    "# Main simulation loop\n",
    "running = True\n",
    "frames = 0\n",
    "sim_iter = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training/simulation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training @ = 21:09:25\n",
      "Training @ = 21:09:41\n",
      "Training @ = 21:09:57\n",
      "Training @ = 21:10:13\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "while running:\n",
    "    frames += 1\n",
    "    if visualize:\n",
    "    # Clear the screen and render the simulation\n",
    "        screen.fill(WHITE)\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "\n",
    "    # Handle collisions and move particles\n",
    "    handle_collisions(particle_list + [object])\n",
    "\n",
    "    # Gather all current states\n",
    "    current_states = np.array([get_state(particle, object, target_pos) for particle in particle_list])\n",
    "\n",
    "    # Batch prediction\n",
    "    actions = model.predict(current_states, verbose=0)\n",
    "\n",
    "    for particle_index, particle in enumerate(particle_list):\n",
    "        action = actions[particle_index][:2]  # Extract the action for this particle\n",
    "        apply_action(action, particle)\n",
    "        particle.physics_move()  # Update physics of this particle\n",
    "\n",
    "        # Calculate reward for this particle\n",
    "        state = get_state(particle, object, target_pos)\n",
    "        done = np.linalg.norm(object.position - target_pos) < (object_radius + target_radius)\n",
    "        reward = calculate_individual_reward(particle, object, target_pos, collision_occurred_with_object, starting_distance_to_target)\n",
    "\n",
    "        # Add experience to the respective particle's replay buffer\n",
    "        replay_buffers[particle_index].add(current_states[particle_index], actions[particle_index], reward, state, done)\n",
    "\n",
    "    # Update object's physics\n",
    "    object.physics_move()\n",
    "\n",
    "    # Decay epsilon if necessary\n",
    "    epsilon = max(epsilon_min, epsilon_decay * epsilon)\n",
    "\n",
    "    # Define a training frequency\n",
    "    training_freq = 100  # Example: Train the model every 100 frames\n",
    "\n",
    "    if frames % training_freq == 0:\n",
    "        train_model(model, replay_buffers, batch_size, gamma)\n",
    "\n",
    "    if visualize:\n",
    "        pygame.display.set_caption(f'Simulation Interation: {sim_iter}    Frame: {frames}')\n",
    "        pygame.draw.rect(screen, BLACK, (0, 0, WIDTH, HEIGHT), 2)\n",
    "        pygame.draw.circle(screen, BLUE, center=(object.position[0], object.position[1]), radius=object.radius)\n",
    "        pygame.draw.circle(screen, GREEN, target_pos.astype(int), target_radius)\n",
    "\n",
    "        for particle in particle_list:\n",
    "            pygame.draw.circle(screen, RED, center=(particle.position[0], particle.position[1]), radius=particle.radius)\n",
    "        \n",
    "        pygame.display.flip()\n",
    "        clock.tick(60)\n",
    "\n",
    "    # End conditions\n",
    "    if done:\n",
    "        consecutive_successes += 1\n",
    "        if consecutive_successes >= 3:\n",
    "            print(\"Model training completed.\")\n",
    "            model.save('particle_swarm_model.h5')\n",
    "            running = False\n",
    "        \n",
    "        #Train model with accumulated experiences\n",
    "        # train_model(model, replay_buffers, batch_size, gamma)\n",
    "        #Reset for new session\n",
    "        print(\"Hey! That worked! Let's do it again!!\")\n",
    "        print(f'Reward: {reward}')\n",
    "        frames, sim_iter, starting_distance_to_target = reset_simulation(particle_list, object, sim_iter)\n",
    "        \n",
    "    elif frames >= max_success_frames:\n",
    "        print('That didnt quite work... lets try again.')\n",
    "        print(replay_buffers[1])\n",
    "        consecutive_successes = 0  # Reset if the task was not completed in time\n",
    "        #Train model with accumulated experiences\n",
    "        # train_model(model, replay_buffers, batch_size, gamma)\n",
    "        #Reset for new session\n",
    "        frames, sim_iter, starting_distance_to_target = reset_simulation(particle_list, object, sim_iter)\n",
    "\n",
    "    if sim_iter > 10:\n",
    "        model.save('model_p10.keras')\n",
    "        print(\"Model training completed.\")\n",
    "        running = False\n",
    "\n",
    "if visualize:\n",
    "    pygame.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
